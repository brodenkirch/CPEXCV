{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b52ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import cm  #to get python's normal library of colormaps\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  #hides \"MatplotlibDeprecationWarning\" with pcolormesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb659d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some baseline plot displays\n",
    "\n",
    "#matplotlib.rcParams['axes.facecolor'] = [0.9,0.9,0.9]\n",
    "matplotlib.rcParams['axes.labelsize'] = 35\n",
    "matplotlib.rcParams['axes.titlesize'] = 45\n",
    "matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "matplotlib.rcParams['xtick.labelsize'] = 27\n",
    "matplotlib.rcParams['ytick.labelsize'] = 27\n",
    "matplotlib.rcParams['legend.fontsize'] = 35\n",
    "#matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "matplotlib.rcParams['font.family'] = 'arial'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab75455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: ['20220910', '20220910,153500', '20220910,180500']\n",
      "Finished: ['20220910', '20220910,153500', '20220910,180500']\n",
      "\n",
      "Working on: ['20220910', '20220910,180500', '20220910,204500']\n",
      "Finished: ['20220910', '20220910,180500', '20220910,204500']\n",
      "\n",
      "Working on: ['20220914', '20220914,101000', '20220914,115500']\n",
      "Finished: ['20220914', '20220914,101000', '20220914,115500']\n",
      "\n",
      "Working on: ['20220914', '20220914,115500', '20220914,142800']\n",
      "Finished: ['20220914', '20220914,115500', '20220914,142800']\n",
      "\n",
      "Working on: ['20220914', '20220914,142800', '20220914,164500']\n",
      "Finished: ['20220914', '20220914,142800', '20220914,164500']\n",
      "\n",
      "Working on: ['20220916', '20220916,143000', '20220916,164000']\n",
      "Finished: ['20220916', '20220916,143000', '20220916,164000']\n",
      "\n",
      "Working on: ['20220916', '20220916,164000', '20220916,183500']\n",
      "Finished: ['20220916', '20220916,164000', '20220916,183500']\n",
      "\n",
      "Working on: ['20220920', '20220920,071000', '20220920,090000']\n",
      "Finished: ['20220920', '20220920,071000', '20220920,090000']\n",
      "\n",
      "Working on: ['20220922', '20220922,054000', '20220922,083000']\n",
      "Finished: ['20220922', '20220922,054000', '20220922,083000']\n",
      "\n",
      "Working on: ['20220923', '20220923,092000', '20220923,115000']\n",
      "Finished: ['20220923', '20220923,092000', '20220923,115000']\n",
      "\n",
      "Working on: ['20220923', '20220923,115000', '20220923,143000']\n",
      "Finished: ['20220923', '20220923,115000', '20220923,143000']\n",
      "\n",
      "Working on: ['20220926', '20220926,072000', '20220926,092000']\n",
      "Finished: ['20220926', '20220926,072000', '20220926,092000']\n",
      "\n",
      "Working on: ['20220926', '20220926,092000', '20220926,111500']\n",
      "Finished: ['20220926', '20220926,092000', '20220926,111500']\n",
      "\n",
      "Working on: ['20220929', '20220929,103500', '20220929,120000']\n",
      "Finished: ['20220929', '20220929,103500', '20220929,120000']\n",
      "\n",
      "Working on: ['20220929', '20220929,120000', '20220929,134500']\n",
      "Finished: ['20220929', '20220929,120000', '20220929,134500']\n",
      "\n",
      "Working on: ['20220930', '20220930,092000', '20220930,102000']\n",
      "Finished: ['20220930', '20220930,092000', '20220930,102000']\n",
      "\n",
      "Working on: ['20220930', '20220930,111000', '20220930,134000']\n",
      "Finished: ['20220930', '20220930,111000', '20220930,134000']\n",
      "\n",
      "Working on: ['20220930', '20220930,134000', '20220930,143000']\n",
      "Finished: ['20220930', '20220930,134000', '20220930,143000']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full = False    #do the chosen time ranges below encapsulate the entire convective module?\n",
    "case_list = [['20220906', '20220906,110000', '20220906,120000'],\n",
    "            ['20220906', '20220906,133000', '20220906,161000'],\n",
    "            ['20220906', '20220906,161000', '20220906,180000'],\n",
    "            ['20220907', '20220907,130000', '20220907,134500'],\n",
    "            ['20220907', '20220907,134500', '20220907,161800'],\n",
    "            ['20220907', '20220907,161800', '20220907,174500'],\n",
    "            ['20220909', '20220909,161000', '20220909,171000'],\n",
    "            ['20220909', '20220909,173500', '20220909,191000'],\n",
    "            ['20220910', '20220910,153500', '20220910,180500'],\n",
    "            ['20220910', '20220910,180500', '20220910,204500'],\n",
    "            ['20220914', '20220914,101000', '20220914,115500'],\n",
    "            ['20220914', '20220914,115500', '20220914,142800'],\n",
    "            ['20220914', '20220914,142800', '20220914,164500'],\n",
    "            ['20220916', '20220916,143000', '20220916,164000'],\n",
    "            ['20220916', '20220916,164000', '20220916,183500'],\n",
    "            ['20220920', '20220920,071000', '20220920,090000'],\n",
    "            ['20220922', '20220922,054000', '20220922,083000'],\n",
    "            ['20220923', '20220923,092000', '20220923,115000'],\n",
    "            ['20220923', '20220923,115000', '20220923,143000'],\n",
    "            ['20220926', '20220926,072000', '20220926,092000'],\n",
    "            ['20220926', '20220926,092000', '20220926,111500'],\n",
    "            ['20220929', '20220929,103500', '20220929,120000'],\n",
    "            ['20220929', '20220929,120000', '20220929,134500'],\n",
    "            ['20220930', '20220930,092000', '20220930,102000'],\n",
    "            ['20220930', '20220930,111000', '20220930,134000'],\n",
    "            ['20220930', '20220930,134000', '20220930,143000']]\n",
    "\n",
    "for start_list in case_list:\n",
    "    \n",
    "    print ('Working on:', start_list)\n",
    "    file_date = start_list[0]    #which date to create the APR plot for\n",
    "    start_time0 = start_list[1]  #start date,time for the APR plot\n",
    "    end_time0 = start_list[2]    #end date,time for the APR plot\n",
    "\n",
    "    #other users will also have to change day_folder, apr_folder, dawn_csv_path, and drop_csv_path filepaths\n",
    "        #dawn_csv_path and drop_csv_path are based on created files from CPEXCV_DAWN.ipynb and CPEXCV_dropsonde(_metrics).ipynb\n",
    "\n",
    "    start_time = datetime.strptime(start_time0, '%Y%m%d,%H%M%S')\n",
    "    end_time = datetime.strptime(end_time0, '%Y%m%d,%H%M%S')\n",
    "\n",
    "    #locations of the APR folder and APR files\n",
    "    day_folder = os.path.join(os.getcwd(), file_date)\n",
    "    apr_folder = os.path.join(day_folder, 'APR_files')\n",
    "\n",
    "    #load the final DAWN and final Dropsonde CSVs\n",
    "    dawn_csv_path = os.path.join(day_folder, 'final_dawn_' + file_date + '.csv')\n",
    "    dawn_csv = pd.read_csv(dawn_csv_path)\n",
    "\n",
    "    drop_csv_path = os.path.join(day_folder, 'final_dropsonde_' + file_date + '.csv')\n",
    "    drop_csv = pd.read_csv(drop_csv_path)\n",
    "\n",
    "    #create a list of all the given day's desired range's APR files:\n",
    "    for x in os.listdir(apr_folder):\n",
    "        if x[0:3] == '.DS':         #delete hidden .DS_Store files if they come up (will show up if you delete a file)\n",
    "            os.remove(os.path.join(apr_folder, x))\n",
    "\n",
    "    #find the starting APR file in apr_folder\n",
    "    first_file_index = None \n",
    "\n",
    "    #sorted() makes sure the code goes through the files in alphabetical (chronological) order\n",
    "    #GOING THROUGH THE FILES IN CHRONOLOGICAL ORDER IS ESSENTIAL FOR THIS CELL TO WORK PROPERLY!!\n",
    "    for i, x in enumerate(sorted(os.listdir(apr_folder))):  \n",
    "        file_start_time = datetime.strptime(x[29:37] + x[38:44], '%Y%m%d%H%M%S')\n",
    "        file_end_time = datetime.strptime(x[46:54] + x[55:61], '%Y%m%d%H%M%S')\n",
    "\n",
    "        if start_time <= file_start_time:  #if start_time is before the APR file start time and not within any previous APR file's time ranges\n",
    "            first_file_index = i\n",
    "            break\n",
    "        elif (start_time >= file_start_time) and (start_time < file_end_time):\n",
    "            first_file_index = i\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    if first_file_index == None:\n",
    "        sys.exit('Requested start_time is beyond all available APR files')\n",
    "\n",
    "    #find the ending APR file in apr_folder\n",
    "    last_file_index = None    \n",
    "\n",
    "    #sorted() makes sure the code goes through the files in alphabetical (chronological) order\n",
    "    #GOING THROUGH THE FILES IN CHRONOLOGICAL ORDER IS ESSENTIAL FOR THIS CELL TO WORK PROPERLY!!\n",
    "    for i, x in enumerate(sorted(os.listdir(apr_folder))):  \n",
    "        file_start_time = datetime.strptime(x[29:37] + x[38:44], '%Y%m%d%H%M%S')\n",
    "        file_end_time = datetime.strptime(x[46:54] + x[55:61], '%Y%m%d%H%M%S')\n",
    "\n",
    "        if end_time <= file_start_time:  #if end_time is before the APR file start time and not within any previous APR file's time ranges\n",
    "            last_file_index = i - 1\n",
    "            break\n",
    "        elif (end_time > file_start_time) and (end_time <= file_end_time):\n",
    "            last_file_index = i\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    if last_file_index == None:  #the end_time is after all available APR file ranges\n",
    "        last_file_index = len(sorted(os.listdir(apr_folder))) - 1  #the last available APR file's index\n",
    "    if last_file_index == -1:\n",
    "        sys.exit('Requested end_time is before all available APR files')\n",
    "\n",
    "    apr_file_list = sorted(os.listdir(apr_folder))[first_file_index:last_file_index + 1]\n",
    "    #apr_file_list\n",
    "\n",
    "    #Calculate time range in minutes, have a tick for each minute\n",
    "    num_minutes = (end_time - start_time).total_seconds() // 60\n",
    "    fig_length = num_minutes * 2\n",
    "\n",
    "    #Calculate height range of the plot, based on the maximum height of all DAWN profiles\n",
    "    height_max = dawn_csv['Height [m]'].max()\n",
    "    y_max = math.ceil(height_max / 1000) * 1000  #round height_max up to the nearest 1000\n",
    "\n",
    "    #plotting a time-series plot of Ku-band reflectivity vs. height\n",
    "    ylim=[0,y_max]\n",
    "    vlim=[-10,40]\n",
    "    vlim2=[-15,15]   #for Ku-band minus Ka-band reflectivity\n",
    "    vel_lim=[-10,10]\n",
    "\n",
    "    #Low resolution ('lores') radar variables in APR hdf files\n",
    "    ku_band = 'lores_zhh14' #Ku-band reflectivity\n",
    "    ka_band = 'lores_zhh35' #Ka-band reflectivity\n",
    "    vel = 'lores_vel14c' #Mean Doppler Velocity from Ku-band (surface Doppler velocity is subtracted and free of aliasing)\n",
    "    w_band = 'lores_z95s' #W-band reflectivity\n",
    "    w_band_nadir = 'hi2lo_z95n' #W-band reflectivity at nadir, upscaled to same resolution as 'lores'\n",
    "        #^^^for quantitative analysis, will likely want to switch to using 'hires_z95n'\n",
    "\n",
    "    if full:\n",
    "        plot_save_name = file_date + '_FivePanel_full.png'\n",
    "    else:\n",
    "        plot_save_name = file_date + '_FivePanel_' + start_time0[-6:] + '-' + end_time0[-6:] + '.png'\n",
    "\n",
    "    fig,axes = plt.subplots(5,1,figsize=(fig_length,60))\n",
    "\n",
    "    for file in apr_file_list:\n",
    "\n",
    "        #find the APR file of interest (for the desired datetime)\n",
    "        apr_filepath = os.path.join(apr_folder, file)\n",
    "        apr_file = xr.open_dataset(apr_filepath)\n",
    "\n",
    "        #grab the radar variables of interest\n",
    "        ku_good = False\n",
    "        if ku_band in apr_file.keys():\n",
    "            try:   #some APR files, at least in the preliminary data, have corrupted Ku-band data; \n",
    "                   #if so, skip plotting the Ku-band for that file\n",
    "                   #corrupted: \"OSError: Can't read data (inflate() failed)\"\n",
    "                ku_data = apr_file[ku_band][:]\n",
    "\n",
    "                #mask the missing Ku-band data (values of -99.99)\n",
    "                ku_masked = np.ma.masked_where(ku_data <= -99, ku_data)\n",
    "                ku_masked = np.ma.masked_where(np.isnan(ku_masked), ku_masked)  #masks NaN values (not masked in previous line)\n",
    "                ku_good = True\n",
    "            except:\n",
    "                ku_good = False\n",
    "\n",
    "        ka_good = False\n",
    "        if ka_band in apr_file.keys():\n",
    "            try:   #some APR files, at least in the preliminary data, have corrupted Ka-band data; \n",
    "                   #if so, skip plotting the Ka-band for that file\n",
    "                   #corrupted: \"OSError: Can't read data (inflate() failed)\"\n",
    "                ka_data = apr_file[ka_band][:]\n",
    "\n",
    "                #mask the missing Ka-band data (values of -99.99)\n",
    "                ka_masked = np.ma.masked_where(ka_data <= -99, ka_data)\n",
    "                ka_masked = np.ma.masked_where(np.isnan(ka_masked), ka_masked)  #masks NaN values (not masked in previous line)\n",
    "                ka_good = True\n",
    "            except:\n",
    "                ka_good = False\n",
    "\n",
    "        w_nadir_good = False\n",
    "        if w_band_nadir in apr_file.keys():  #nadir-only W-band data\n",
    "            try:   #some APR files, at least in the preliminary data, have corrupted W-band data; \n",
    "                   #if so, skip plotting the W-band for that file\n",
    "                   #corrupted: \"OSError: Can't read data (inflate() failed)\"\n",
    "                w_nadir_data = apr_file[w_band_nadir][:]\n",
    "\n",
    "                #mask the missing W-band data (values of -99.99)\n",
    "                w_nadir_masked = np.ma.masked_where(w_nadir_data <= -99, w_nadir_data)\n",
    "                w_nadir_masked = np.ma.masked_where(np.isnan(w_nadir_masked), w_nadir_masked)  #masks NaN values (not masked in previous line)\n",
    "                w_nadir_good = True\n",
    "            except:\n",
    "                w_nadir_good = False\n",
    "\n",
    "        w_good = False\n",
    "        if w_band in apr_file.keys():\n",
    "            try:   #some APR files, at least in the preliminary data, have corrupted W-band data; \n",
    "                   #if so, skip plotting the W-band for that file\n",
    "                   #corrupted: \"OSError: Can't read data (inflate() failed)\"\n",
    "                w_data = apr_file[w_band][:]\n",
    "\n",
    "                #mask the missing W-band data (values of -99.99)\n",
    "                w_masked = np.ma.masked_where(w_data <= -99, w_data)\n",
    "                w_masked = np.ma.masked_where(np.isnan(w_masked), w_masked)  #masks NaN values (not masked in previous line)\n",
    "                w_good = True\n",
    "            except:\n",
    "                w_good = False\n",
    "\n",
    "        vel_good = False\n",
    "        if vel in apr_file.keys():\n",
    "            try:   #some APR files, at least in the preliminary data, have corrupted Velocity data; \n",
    "                   #if so, skip plotting velocity for that file\n",
    "                   #corrupted: \"OSError: Can't read data (inflate() failed)\"\n",
    "                vel_data = apr_file[vel][:]\n",
    "\n",
    "                #mask the missing Velocity data (values < -30 (changed from original -99.99))\n",
    "                vel_masked = np.ma.masked_where(vel_data <= -99, vel_data)\n",
    "                vel_masked = np.ma.masked_where(np.isnan(vel_masked), vel_masked)  #masks NaN values (not masked in previous line)\n",
    "                vel_good = True\n",
    "            except:\n",
    "                vel_good = False \n",
    "\n",
    "        #if Ku-band or Ka-band or W-band or Doppler Velocity is available\n",
    "        if ku_good or ka_good or w_nadir_good or w_good or vel_good:            \n",
    "\n",
    "            #Convert 'lo-res' APR times to datetimes\n",
    "            time = apr_file['time'][:]  #For 'lores': Time of scan, in seconds since midnight UTC of [YYYY-mm-DD]\n",
    "            alt3d = apr_file['lores_alt3D'][:]\n",
    "\n",
    "            time_dates = np.empty(time.shape, dtype=object)\n",
    "            for i in np.arange(0, time.shape[0]):\n",
    "                #hour, second automatically revert to midnight (hour = 0, seconds = 0) for '%Y%m%d'\n",
    "                time_dates[i] = datetime.strptime(file_date, '%Y%m%d') + timedelta(seconds = float(time[i].values))\n",
    "\n",
    "            #Create a time at each gate (assuming time is the same for each ray of a given scan and down each ray)      \n",
    "            time_gate = np.empty(alt3d.shape, dtype=object)\n",
    "            for i in np.arange(0, alt3d.shape[0]):\n",
    "                time_gate[i,:,:] = time_dates[i]   #assign the same time to all of a given scan's rays and height bins     \n",
    "\n",
    "            time3d = np.copy(time_gate)\n",
    "\n",
    "    #         print (time3d[0,0,:])  #times should be the same\n",
    "    #         print ('')\n",
    "    #         print (time3d[0,:,0])  #times should be the same\n",
    "    #         print ('')\n",
    "    #         print (time3d[:,0,0])  #times should be different\n",
    "    #         sys.exit()\n",
    "\n",
    "            #plot the APR data factoring in the aircraft roll (ray adjustment)\n",
    "            #choose the \"pseudo-nadir\" ray factoring in aircraft roll\n",
    "            roll = apr_file['lores_roll'][:]\n",
    "            ray_angles = np.arange(-25,25.01,25/12)  #in degrees; 25 rays for each scan, with the middle (13th) scan being zero degrees\n",
    "            for scan in range(roll.shape[0]):\n",
    "                if (time_dates[scan] >= start_time) and (time_dates[scan] <= end_time):\n",
    "                    ac_roll = np.nanmean(roll[scan,:])  #roll varies slightly w/ray, so take the average roll value for a given scan and use that for ray adjustment\n",
    "                    ray_use = np.argmin(np.abs(ray_angles - ac_roll))  #the index of the ray whose angle is closest to that of ac_roll    \n",
    "\n",
    "                    #scan + 2 (and not scan + 1) is needed because pcolormesh colors the grid cell from the  \n",
    "                    #grid cell's time to the subsequent grid cell's time.  If a subsequent grid cell does not exist,  \n",
    "                    #then pcolormesh cannot/doesn't color the grid cell (remember, slicing is right side EXCLUSIVE, \n",
    "                    #so scan:scan + 1 is only 1 element and thus doesn't have a subsequent cell!)\n",
    "                    #by this same logic, scan:scan + 2 will only color one grid cell, since the 2nd (and last) \n",
    "                    #element/grid cell doesn't have a subsequent grid cell\n",
    "\n",
    "                    if ku_good:\n",
    "                        pm0 = axes[0].pcolormesh(time3d[scan:scan+2,ray_use,:], alt3d[scan:scan+2,ray_use,:],\n",
    "                                                 ku_masked[scan:scan+2,ray_use,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "                    if ka_good:\n",
    "                        pm1 = axes[1].pcolormesh(time3d[scan:scan+2,ray_use,:], alt3d[scan:scan+2,ray_use,:],\n",
    "                                                 ka_masked[scan:scan+2,ray_use,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "                    if vel_good:\n",
    "                        pm2 = axes[2].pcolormesh(time3d[scan:scan+2,ray_use,:], alt3d[scan:scan+2,ray_use,:],\n",
    "                                                 vel_masked[scan:scan+2,ray_use,:], cmap=cm.seismic,vmin=vel_lim[0],vmax=vel_lim[1])\n",
    "                    if ku_good and ka_good:\n",
    "                        pm4 = axes[4].pcolormesh(time3d[scan:scan+2,ray_use,:], alt3d[scan:scan+2,ray_use,:],\n",
    "                                                 (ku_masked - ka_masked)[scan:scan+2,ray_use,:], cmap=cm.seismic,vmin=vlim2[0],vmax=vlim2[1])\n",
    "\n",
    "                    #prioritize plotting the 'lores' W-band over the 'hires'/'hi2lo' nadir W-band    \n",
    "                    if w_good:\n",
    "                        pm3 = axes[3].pcolormesh(time3d[scan:scan+2,ray_use,:], alt3d[scan:scan+2,ray_use,:],\n",
    "                                                 w_masked[scan:scan+2,ray_use,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "                    elif w_nadir_good:\n",
    "                        alt3d_nadir = apr_file['hi2lo_alt3D'][:]\n",
    "                        try:\n",
    "                            pm3 = axes[3].pcolormesh(time3d[scan:scan+2,12,:], alt3d_nadir[scan:scan+2,12,:], \n",
    "                                                     w_nadir_masked[scan:scan+2,12,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "                        except:  #if alt3d_nadir has no height data for the given scan, then just use alt3d which is essentially the same with only extremely minor height differences (if any)\n",
    "                            pm3 = axes[3].pcolormesh(time3d[scan:scan+2,12,:], alt3d[scan:scan+2,12,:], \n",
    "                                                     w_nadir_masked[scan:scan+2,12,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "                        #except ValueError:\n",
    "                            #print ('For', time3d[scan,12,0], 'x and y arguments to pcolormesh cannot have non-finite values or be of type numpy.ma.core.MaskedArray with masked values')\n",
    "                            ##the weird error above is caused by \"_Wn.nc\" files I believe\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "#                     #using .scatter() instead of pcolormesh more than doubles the file size\n",
    "#                     #if you want to keep the file size similar to pcolormesh, use Image.convert (last section of code)\n",
    "#                     if ku_good:\n",
    "#                         pm0 = axes[0].scatter(time3d[scan,ray_use,:], alt3d[scan,ray_use,:],\n",
    "#                                                  c = ku_masked[scan,ray_use,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "#                     if ka_good:\n",
    "#                         pm1 = axes[1].scatter(time3d[scan,ray_use,:], alt3d[scan,ray_use,:],\n",
    "#                                                  c = ka_masked[scan,ray_use,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "#                     if vel_good:\n",
    "#                         pm2 = axes[2].scatter(time3d[scan,ray_use,:], alt3d[scan,ray_use,:],\n",
    "#                                                  c = vel_masked[scan,ray_use,:], cmap=cm.seismic,vmin=vel_lim[0],vmax=vel_lim[1])\n",
    "#                     if ku_good and ka_good:\n",
    "#                         pm4 = axes[4].scatter(time3d[scan,ray_use,:], alt3d[scan,ray_use,:],\n",
    "#                                                  (ku_masked - ka_masked)[scan,ray_use,:], cmap=cm.seismic,vmin=vlim2[0],vmax=vlim2[1])\n",
    "\n",
    "#                     #prioritize plotting the 'lores' W-band over the 'hires'/'hi2lo' nadir W-band\n",
    "#                     if w_good:\n",
    "#                         pm3 = axes[3].scatter(time3d[scan,ray_use,:], alt3d[scan,ray_use,:],\n",
    "#                                                  c = w_masked[scan,ray_use,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "#                     elif w_nadir_good:\n",
    "#                         alt3d_nadir = apr_file['hi2lo_alt3D'][:]\n",
    "#                         try:\n",
    "#                             pm3 = axes[3].scatter(time3d[scan,12,:], alt3d_nadir[scan,12,:],\n",
    "#                                                      c = w_nadir_masked[scan,12,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "#                         except:  #if alt3d_nadir has no height data for the given scan, then just use alt3d which is essentially the same with only extremely minor height differences (if any)\n",
    "#                             pm3 = axes[3].pcolormesh(time3d[scan:scan+2,12,:], alt3d[scan:scan+2,12,:], \n",
    "#                                                      w_nadir_masked[scan:scan+2,12,:], cmap=cm.Spectral_r,vmin=vlim[0],vmax=vlim[1])\n",
    "#                         #except ValueError:\n",
    "#                             #print ('For', time3d[scan,12,0], 'x and y arguments to pcolormesh cannot have non-finite values or be of type numpy.ma.core.MaskedArray with masked values')\n",
    "#                             ##the weird error above is caused by \"_Wn.nc\" files I believe\n",
    "#                     else:\n",
    "#                         pass\n",
    "\n",
    "        apr_file.close()\n",
    "\n",
    "    try:\n",
    "        cbar0 = plt.colorbar(pm0, ax=axes[0], pad = 0.01)\n",
    "        cbar0.set_label('Z [dBZ]')\n",
    "    except NameError:  #the desired time range didn't have any good Ku-band data\n",
    "        pass\n",
    "    axes[0].set_title('Ku-band Reflectivity')\n",
    "\n",
    "    try:\n",
    "        cbar1 = plt.colorbar(pm1, ax=axes[1], pad = 0.01)\n",
    "        cbar1.set_label('Z [dBZ]')\n",
    "    except NameError:  #the desired time range didn't have any good Ka-band data\n",
    "        pass\n",
    "    axes[1].set_title('Ka-band Reflectivity')\n",
    "\n",
    "    try:\n",
    "        cbar2 = plt.colorbar(pm2, ax=axes[2], pad = 0.01)\n",
    "        cbar2.set_label('Doppler Velocity [m s$^{-1}$]')\n",
    "    except NameError:  #the desired time range didn't have any good Doppler velocity data\n",
    "        pass\n",
    "    axes[2].set_title('Doppler Velocity')\n",
    "\n",
    "    try:\n",
    "        cbar3 = plt.colorbar(pm3, ax=axes[3], pad = 0.01)\n",
    "        cbar3.set_label('Z [dBZ]')\n",
    "    except NameError:  #the desired time range didn't have any good W-band data\n",
    "        pass\n",
    "    axes[3].set_title('W-band Reflectivity')\n",
    "    \n",
    "    try:\n",
    "        cbar4 = plt.colorbar(pm4, ax=axes[4], pad = 0.01)\n",
    "        cbar4.set_label('[dB]')\n",
    "    except NameError:  #the desired time range didn't have any good Ku- AND Ka-band data\n",
    "        pass\n",
    "    axes[4].set_title('Ku- minus Ka- Reflectivity')\n",
    "\n",
    "    dawn_skip = slice(None,None,7)   #only plot every 7th DAWN value\n",
    "    drop_skip = slice(None,None,20)  #only plot every 20th dropsonde value\n",
    "\n",
    "    #set the plot start time as the beginning time of the first APR file and the\n",
    "        #plot end time as the end time of the last APR file:\n",
    "    # range_start = datetime.strptime(apr_file_list[0][32:40] + apr_file_list[0][41:47], '%Y%m%d%H%M%S') \n",
    "    # range_end = datetime.strptime(apr_file_list[-1][49:57] + apr_file_list[-1][58:64], '%Y%m%d%H%M%S')\n",
    "    range_start = start_time\n",
    "    range_end = end_time\n",
    "\n",
    "    for i in range(5):\n",
    "        axes[i].barbs(pd.to_datetime(dawn_csv['Time [UTC]'])[dawn_skip], dawn_csv['Height [m]'][dawn_skip], \n",
    "                      dawn_csv['U Comp of Wind [m/s]'][dawn_skip], dawn_csv['V Comp of Wind [m/s]'][dawn_skip], \n",
    "                      fill_empty = True, length = 7, pivot='middle', sizes=dict(emptybarb=0.075), barbcolor = 'k')\n",
    "        axes[i].barbs(pd.to_datetime(drop_csv['Time [UTC]'])[drop_skip], drop_csv['Height [m]'][drop_skip], \n",
    "                      drop_csv['U Comp of Wind [m/s]'][drop_skip], drop_csv['V Comp of Wind [m/s]'][drop_skip], \n",
    "                      fill_empty = True, length = 7, pivot='middle', sizes=dict(emptybarb=0.075), barbcolor = 'b')\n",
    "        axes[i].set_ylabel('Altitude [m]')\n",
    "        axes[i].set_xlabel('Time [UTC]')\n",
    "        axes[i].set_ylim([ylim[0],ylim[1]])\n",
    "        axes[i].tick_params(axis='x', rotation = 50)\n",
    "        axes[i].tick_params(length = 15, width = 5)\n",
    "        axes[i].xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%H:%M:%S\"))\n",
    "        axes[i].xaxis.set_major_locator(ticker.MaxNLocator(num_minutes))      #sets number of ticks\n",
    "        axes[i].set_xlim([np.datetime64(range_start),np.datetime64(range_end)])    \n",
    "            #use the above line to narrow the plot's time range (even within a file!!)\n",
    "                #range_start and range_end must be a datetime object or a string with the \n",
    "                    #format: 'YYYY-MM-DD HH:MM:SS' or 'YYYY-MM-DDTHH:MM:SS'\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0.40)\n",
    "\n",
    "    #save the figure\n",
    "    plt.savefig(os.path.join(day_folder, plot_save_name), bbox_inches = 'tight')\n",
    "    #plt.show()  #if you want to also show the image in the output cell, plt.show() must come after plt.savefig() in order for the image to save properly\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ##decrease file size of the image by 66% without noticeable image effects (if using Matplotlib)\n",
    "    ##(good to use if you're producing a lot of images, see https://www.youtube.com/watch?v=fzhAseXp5B4)\n",
    "    from PIL import Image\n",
    "    im = Image.open(os.path.join(day_folder, plot_save_name))\n",
    "\n",
    "    try:\n",
    "        im2 = im.convert('P', palette = Image.Palette.ADAPTIVE)\n",
    "    except:\n",
    "        #use this for older version of PIL/Pillow if the above line doesn't work, \n",
    "        #though this line will have isolated, extremely minor image effects due to \n",
    "        #only using 256 colors instead of the 3-element RGB scale\n",
    "        im2 = im.convert('P')\n",
    "\n",
    "    im2.save(os.path.join(day_folder, plot_save_name))\n",
    "    im.close()\n",
    "    im2.close()\n",
    "    \n",
    "    print ('Finished:', start_list)\n",
    "    print ('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aff61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
